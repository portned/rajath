---
layout: post
title:  "Understanding Principal Component Analysis"
date:   2015-02-11 20:21:21
categories: Understanding
tags: PCA
image: /assets/images/antivj10.jpg
permalink: /PCA/
---

####Prologue
In this post I will try to breakdown Principal Component Analysis into bits one can easily understand. For a better understanding I will do a quick walkthrough about the important mathematical concepts that you might have studied but haven't used it in real world applications. In the end I will talk about implementing Principal Component Analysis in Python, How to use the same for image compression and in a separate post will talk about using PCA with neural networks for facial recognition.
####Principal Component Analysis
It is the oldest and the most widely used statistical multivariate technique which finds a pattern in the data under consideration. PCA can be further extended towards dimensionality reduction by extracting important features which are necessary to the given problem statement and ignoring the ones which aren't. It find's its application in face recognition, Image compression, Dimensionality reduction etc.

Let us get into the nitty gritty, First I will explain by taking an example and applying PCA to a simple one dimensional dataset. Further will take two dimensions and extend it to multi dimensions.

Consider a data set that you would like to study. As an example let us take some random **one dimensional** dataset _X_
		
	X = { 5,2,3,9,1,4 }

Now calculating the **mean** of _X_ with _n_ number of data by using the formula

$${\bar{X} = \frac{ \sum_ {i=1}^n X_i}{n}}$$

Thus, The mean, \\(\bar{X}\\) will now be equal to _4_. Mean as everybody knows it gives the center point of the dataset or the average of the entire dataset.

Now consider another dataset 

	Y = { 5,3,2,7,2,5 }

Notice the mean, \\(\bar{Y}\\) of this dataset is also _4_. So now how do you know how these two data is different? Or how it varies?

**Standard Deviation**. Wikipedia defines it as _"A measure that is used to quantify the amount of variation or dispersion of a set of data values"_ which simply means it gives a picture about how the data varies with respect to the mean. For the _X_ dataset standard deviation is given by the formula

$$SD = \sqrt{\frac{ \sum_ {i=1}^n {(X_i-\bar{X})^2}}{(n-1)}}$$

Took me sometime to understand as to why `(n-1)` is used. Wikipedia has the [perfect explanation](https://en.wikipedia.org/wiki/Standard_deviation). As of now, Understand it is Bessel's correction and applying it would give a better answer.

Now **variance** is nothing but the the square of standard deviation.

$$var = SD^2$$

or

$$var={\frac{ \sum_ {i=1}^n {(X_i-\bar{X})^2}}{(n-1)}}$$

The variance of _X_ is 8 and that of _Y_ is 4. Which tells us that the data of _X_ is more varied or spread across than the data of _Y_

Now let us consider two dimensional data, `(X,Y)` say

| X | _2_ | _3_ | _5_ | _7_ | _2_ | _1_ |
|---|:--:|--:| --:| --:| --:| --:|
| **Y** | _**1**_ | _**4**_ | _**8**_ | _**7**_ | _**1**_ | _**3**_ |

Repeat the same process as it was done for one dimensional data set by considering _X_ and _Y_ separate.
We will yield the following result,

Mean of X,		\\(\bar{X}\\) = 3.3335

Mean of Y,		\\(\bar{Y}\\) = 4.0

Variance of X,		\\(X_{var}\\) = 5.0667

Variance of Y,		\\(Y_{var}\\) = 8.8

cov is 5.6

Now we will introduce another parameter that will give the relation between the two dimensions. **Covariance**.

Covariance can be understood as variance but between two parameters and not by itself. Hence defined as

$$cov(X,Y) = {\frac{ \sum_ {i=1}^n{(X_i-\bar{X})}{(Y-\bar{Y})}}{(n-1)}}$$

If you observe covariance and variance formula we can conclude that the covariance of itself that is cov(X,X) is nothing but the variance of X. ( If you did not understand, rewrite the above formula for cov(X,X) and you will see for yourself).

In the dataset under considerstion we can represent the same in a matrix. This matrix is also called as the variance-covariance matrix.

$$\begin{pmatrix} cov(X,X) & cov(X,Y) \\ cov(Y,X) & cov(Y,Y) \end{pmatrix}$$

\begin{pmatrix} x & y \\ z & v \end{pmatrix}

$$ \left( \begin{array}{ccc}
a & b & c \\
d & e & f \\
g & h & i \end{array} \right)$$

$$\begin{bmatrix} x & y \\ z & v \end{bmatrix}$$

$$\left( \begin{array}{ccc}a & b & c \\ d & e & f \\ g & h & i \end{array} \right)$$

 

